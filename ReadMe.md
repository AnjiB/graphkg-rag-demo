# Document QA App with Interactive Knowledge Graph

A powerful AI-powered application that lets you upload documents, ask questions, and explore knowledge through interactive visualizations. Perfect for researchers, students, and anyone who wants to quickly understand and explore document content.

## ğŸŒŸ What This App Does

- **Upload Documents**: Support for PDF, text, code, and data files
- **Ask Questions**: Get AI-powered answers about your documents
- **Source Transparency**: Know whether answers come from your documents or AI's general knowledge
- **Visual Knowledge Graph**: See how concepts connect in your documents
- **Persistent Storage**: Your data stays available between sessions
- **Interactive Exploration**: Click and explore document chunks and relationships
- **Smart UI**: Intuitive interface with loading states and clear feedback

## ğŸ“‹ Supported File Types

- **Documents**: PDF, TXT, Markdown (.md)
- **Code Files**: Python (.py), JavaScript (.js), HTML (.html), CSS (.css)
- **Data Files**: JSON (.json), XML (.xml)

## ğŸš€ Quick Start Guide

### Step 1: Install Required Software

#### 1.1 Install Python (3.11 or newer)
- **Windows**: Download from [python.org](https://www.python.org/downloads/)
- **Mac**: Use Homebrew: `brew install python@3.11`
- **Linux**: `sudo apt install python3.11` (Ubuntu/Debian)

#### 1.2 Install Node.js (16 or newer)
- **All Platforms**: Download from [nodejs.org](https://nodejs.org/)
- **Mac**: `brew install node`
- **Linux**: `sudo apt install nodejs npm`

#### 1.3 Install Docker
- **All Platforms**: Download from [docker.com](https://www.docker.com/products/docker-desktop/)
- **Mac**: `brew install --cask docker`
- **Linux**: Follow [Docker installation guide](https://docs.docker.com/engine/install/)

#### 1.4 Install Poetry (Python package manager)
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

#### 1.5 Install Ollama (AI model runner)
```bash
# Mac/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows: Download from ollama.com
```

### Step 2: Download and Setup the App

1. **Clone or download this project**
2. **Open terminal/command prompt in the project folder**

### Step 3: Start Required Services

#### 3.1 Start Neo4j Database
```bash
docker run -d --name neo4j \
  -p 7474:7474 \
  -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/Test1234 \
  neo4j:latest
```

#### 3.2 Download AI Model
```bash
ollama pull phi3
```

### Step 4: Install App Dependencies

#### 4.1 Backend Setup
```bash
cd src/backend
poetry install
```

#### 4.2 Frontend Setup
```bash
cd src/frontend
npm install
```

### Step 5: Run the Application

#### 5.1 Start Backend (Terminal 1)
```bash
cd src/backend
poetry run uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### 5.2 Start Frontend (Terminal 2)
```bash
cd src/frontend
npm start
```

### Step 6: Access the App
- **Main App**: Open [http://localhost:3000](http://localhost:3000) in your browser
- **API Documentation**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **Database Browser**: [http://localhost:7474](http://localhost:7474) (neo4j/Test1234)

## ğŸ¯ How to Use

### 1. Upload a Document
- Click "Choose File" and select any supported document
- See file selection confirmation and upload button becomes enabled
- Click "Upload Document" (shows "Uploading..." while processing)
- File input clears automatically after successful upload

### 2. Ask Questions
- Type your question in the text box
- Click "Ask Question" (button is disabled while processing)
- Get AI-powered answers with source transparency:
  - ğŸ“„ **Document-based**: Answer comes from your uploaded files
  - ğŸ¤– **General Knowledge**: Answer comes from AI's training data
- Relevant concepts are highlighted in the knowledge graph

### 3. Explore Data
- Click "View Chunks & Knowledge Graph" to see:
  - Document chunks (text segments)
  - Interactive knowledge graph showing concept relationships

### 4. Visual Exploration
- Click and drag nodes in the knowledge graph
- Zoom in/out to explore relationships
- Relevant concepts are highlighted when you ask questions

## ğŸ”§ Troubleshooting

### Common Issues and Solutions

#### "Port already in use" Error
- **Solution**: Stop other applications using ports 3000, 8000, 7474, or 7687
- **Check**: `lsof -i :3000` (Mac/Linux) or `netstat -ano | findstr :3000` (Windows)

#### "Module not found" Error
- **Solution**: Make sure you're in the correct directory and ran `poetry install`
- **Check**: `poetry --version` should work

#### "Docker not running" Error
- **Solution**: Start Docker Desktop application
- **Check**: `docker ps` should show running containers

#### "Ollama model not found" Error
- **Solution**: Run `ollama pull phi3` to download the AI model
- **Check**: `ollama list` should show phi3 model

#### App won't start
- **Solution**: Make sure all services are running:
  - Neo4j: `docker ps | grep neo4j`
  - Backend: Check terminal for "Application startup complete"
  - Frontend: Check terminal for "Compiled successfully"

### Getting Help

1. **Check the logs** in your terminal windows
2. **Verify all services** are running (see Step 5)
3. **Restart services** if needed:
   - Backend: Ctrl+C, then run the uvicorn command again
   - Frontend: Ctrl+C, then run `npm start` again
   - Neo4j: `docker restart neo4j`

## ğŸ—ï¸ Technical Details

### Architecture
- **Frontend**: React 18 with modern UI components
- **Backend**: FastAPI with automatic API documentation
- **AI**: Ollama with Phi-3 model for question answering
- **Vector Database**: ChromaDB for document embeddings
- **Graph Database**: Neo4j for knowledge graph storage
- **Document Processing**: LangChain for text chunking and processing

### Key Features
- **Multi-format Support**: PDF, TXT, MD, PY, JS, HTML, CSS, JSON, XML
- **Source Detection**: Automatically identifies answer sources (documents vs. general knowledge)
- **Persistent Storage**: Data survives app restarts
- **Real-time Processing**: Instant document analysis with loading indicators
- **Interactive Visualization**: Dynamic knowledge graph exploration
- **AI-Powered QA**: Context-aware question answering
- **Smart UI**: Button states, file selection feedback, and clear error handling
- **Security**: Protection against malicious inputs and script injection

### File Structure
```
graphkg-rag-demo/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/           # Python FastAPI backend
â”‚   â”‚   â”œâ”€â”€ main.py       # Main application
â”‚   â”‚   â”œâ”€â”€ utils.py      # Document processing
â”‚   â”‚   â””â”€â”€ kg_db.py      # Database operations
â”‚   â””â”€â”€ frontend/         # React frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ App.jsx   # Main component
â”‚       â”‚   â””â”€â”€ App.css   # Styling
â”‚       â””â”€â”€ public/
â”‚           â””â”€â”€ index.html
â”œâ”€â”€ pyproject.toml        # Python dependencies
â””â”€â”€ README.md            # This file
```

## ğŸ”„ Data Persistence

Your uploaded documents and knowledge graphs are automatically saved and will be available the next time you start the app. No need to re-upload documents!

## âœ¨ Recent Features

### Source Transparency
- **Document-based answers**: Clearly marked with ğŸ“„ icon and green indicator
- **General knowledge answers**: Marked with ğŸ¤– icon and warning message
- **Smart detection**: Automatically identifies whether answers come from your documents or AI's training data

### Enhanced User Experience
- **Smart button states**: Upload button disabled until file selected, Ask button disabled while processing
- **Loading indicators**: Clear feedback during document processing and question answering
- **File selection feedback**: Visual confirmation when files are selected
- **Auto-clear inputs**: File input clears after successful upload

### Security Improvements
- **Input validation**: Protection against malicious inputs and script injection
- **Safe processing**: Script tags and JavaScript code are handled securely
- **Error handling**: Clear error messages for unsupported file types

## ğŸ¨ Customization

### Changing AI Model
Edit `src/backend/main.py` and change `model="phi3"` to another Ollama model:
```python
llm = Ollama(model="llama2")  # or any other model
```

### Adjusting Text Chunking
Edit `src/backend/utils.py` to change chunk size:
```python
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
```